# === LLM Provider API Keys ===
# Azure OpenAI
AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
AZURE_OPENAI_KEY="your-aoai-key"
AZURE_OPENAI_MODEL="gpt-4o" # Default chat model
AZURE_OPENAI_EMBEDDING_MODEL="text-embedding-3-large" # Embeddings model

# OpenAI API
OPENAI_API_KEY="sk-yourOpenAIkey"
# OPENAI_MODEL="gpt-4" # Alternative model

# Google Vertex AI (Gemini)
GOOGLE_APPLICATION_CREDENTIALS="/app/credentials/gcp-credentials.json" # Path inside backend container
VERTEX_PROJECT_ID="your-gcp-project-id"
VERTEX_LOCATION="us-central1"
# VERTEX_MODEL="gemini-2.5-pro"

# === Storage ===
# Azure File Share (for cloned repos, user uploads)
AZURE_STORAGE_CONNECTION_STRING="DefaultEndpointsProtocol=https;AccountName=yourstorageaccount;AccountKey=youraccountkey;EndpointSuffix=core.windows.net"
AZURE_FILE_SHARE_NAME="projectraguploads" # File share for user uploads and processed repos
STORAGE_ACCOUNT="yourstorageaccount" # For local CIFS mount if used
STORAGE_KEY="youraccountkey" # For local CIFS mount if used
# MOUNT_PATH is used by the application to construct paths, e.g. /mnt/uploads
# Actual mounting is defined in docker-compose.yml for local, and IaC for cloud.
MOUNT_PATH="/mnt/projectrag/uploads"
MAX_UPLOAD_MB=250

# Qdrant Vector Database
QDRANT_URL="http://qdrant:6333"
QDRANT_COLLECTION_NAME="project_rag_collection"

# PostgreSQL Database
DATABASE_CONNECTION_STRING="Host=postgres;Port=5432;Database=ragworkspace;Username=postgres;Password=yoursecurepassword"

# Redis (Optional for Caching/Messaging)
REDIS_CONNECTION_STRING="redis:6379"

# === GitHub Integration ===
GITHUB_TOKEN="ghp_yourpersonaaccesstoken" # For backend to clone private repos if needed
GITHUB_CLIENT_ID="your_github_oauth_app_client_id" # For user OAuth flow
GITHUB_CLIENT_SECRET="your_github_oauth_app_client_secret"

# === Security ===
JWT_SECRET="your_very_strong_jwt_secret_key_at_least_32_characters_long_and_random"
JWT_ISSUER="project-rag.com"
JWT_AUDIENCE="project-rag.com/api"

# Frontend / NextAuth
NEXTAUTH_URL="http://localhost:3000" # For local dev
NEXTAUTH_SECRET="your_strong_nextauth_secret_for_session_encryption"
NEXT_PUBLIC_API_URL="http://localhost:8080" # Points to backend

# === Application Settings ===
ALLOWED_ORIGINS="http://localhost:3000" # Comma-separated for multiple
DEFAULT_LLM_PROVIDER="azure-openai" # e.g., azure-openai, openai, google-gemini
DEFAULT_CHAT_MODEL="gpt-4o" # Default model if not specified by user